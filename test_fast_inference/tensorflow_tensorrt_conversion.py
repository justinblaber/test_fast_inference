# AUTOGENERATED! DO NOT EDIT! File to edit: tensorflow_tensorrt_conversion.ipynb (unless otherwise specified).

__all__ = ['conv_layer', 'up_conv_layer', 'get_encoder', 'UNET_TRT']

# Cell
import tensorflow as tf
import tensorflow_addons as tfa

# Cell
def conv_layer(in_channels, out_channels, kernel_size, stride):
    return tf.keras.Sequential([
        tf.keras.layers.Conv2D(out_channels,
                               kernel_size,
                               stride,
                               padding='same',
                               input_shape=(None, None, in_channels)),
        tfa.layers.InstanceNormalization(),
        tf.keras.layers.ReLU()
    ])

# Cell
def up_conv_layer(in_channels, out_channels, kernel_size, stride, scale_factor):
    return tf.keras.Sequential([
        conv_layer(in_channels, out_channels, kernel_size, stride),
        tf.keras.layers.Conv2DTranspose(out_channels,
                                        kernel_size,
                                        strides=2,
                                        padding='same',
                                        input_shape=(None, None, out_channels))
    ])

# Cell
def get_encoder(in_channels, layout_encoder):
    prev_out_channels = in_channels
    encoder = []
    for layout_layer in layout_encoder:
        layer = []
        for layout_conv in layout_layer:
            layer.append(conv_layer(prev_out_channels, *layout_conv))
            prev_out_channels = layout_conv[0]
        encoder.append(tf.keras.Sequential(layer))
    return tf.keras.Sequential(encoder)

# Cell
class UNET_TRT(tf.keras.Model):
    def __init__(self, encoder, out_channels):
        super().__init__()
        self.encoder = encoder
        self.decoder = self._get_decoder(encoder)
        self.last_conv = tf.keras.layers.Conv2D(out_channels,
                                                kernel_size=3,
                                                strides=1,
                                                padding='same',
                                                input_shape=(None, None, self.decoder[-1].output_shape[-1]))

    def _get_decoder(self, encoder):
        # Assumes each level of encoder shrinks by a factor of 2
        decoder = []
        for l in reversed(encoder.layers):
            in_channels = l.output_shape[-1]
            if len(decoder) > 0: in_channels += decoder[-1].output_shape[-1]
            decoder.append(up_conv_layer(in_channels,
                                         out_channels=l.output_shape[-1]//2,
                                         kernel_size=3,
                                         stride=1,
                                         scale_factor=2))
        return decoder

    def call(self, X, training=False):
        Xs = [X]
        for conv_down in self.encoder.layers:
            Xs.append(conv_down(Xs[-1]))
        X = Xs[-1][:,:,:,0:0] # Empty, but same size and dimension as last X
        for idx, conv_up in enumerate(self.decoder):
            X = conv_up(tf.concat([X, Xs[-(idx+1)]], 3))
        return self.last_conv(X)