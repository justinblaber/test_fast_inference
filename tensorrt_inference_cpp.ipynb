{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is meant to be essentially a direct C++ port of `tensorrt_inference_py.ipynb`. \n",
    "\n",
    "Getting TensorRT and Torchlib working with xeus-cling was a near hellish experience, but if it gets to the point where jupyter-notebooks work nicely with C++, that will be incredibly exciting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.504150Z",
     "start_time": "2020-10-20T21:04:21.503814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_library_path(\"/home/justin/TensorRT-7.2.0.14/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.506680Z",
     "start_time": "2020-10-20T21:04:21.506468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/home/justin/TensorRT-7.2.0.14/include\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.529102Z",
     "start_time": "2020-10-20T21:04:21.508974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling load(\"libnvinfer\")\n",
    "#pragma cling load(\"libnvinfer_plugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.529489Z",
     "start_time": "2020-10-20T21:04:21.529268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_library_path(\"/usr/local/cuda/lib64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.529816Z",
     "start_time": "2020-10-20T21:04:21.529603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/usr/local/cuda/include\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.530351Z",
     "start_time": "2020-10-20T21:04:21.529920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling load(\"libcudart\")\n",
    "#pragma cling load(\"libcublas\")\n",
    "#pragma cling load(\"libcudnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Libtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.530612Z",
     "start_time": "2020-10-20T21:04:21.530465Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_library_path(\"/home/justin/pytorch/torch/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.530868Z",
     "start_time": "2020-10-20T21:04:21.530719Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/home/justin/pytorch/torch/include\")\n",
    "#pragma cling add_include_path(\"/home/justin/pytorch/torch/include/torch/csrc/api/include\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.664908Z",
     "start_time": "2020-10-20T21:04:21.530969Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling load(\"libtorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.665274Z",
     "start_time": "2020-10-20T21:04:21.665058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_library_path(\"/usr/local/lib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.665530Z",
     "start_time": "2020-10-20T21:04:21.665385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/usr/local/include/opencv4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:21.667602Z",
     "start_time": "2020-10-20T21:04:21.665636Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pragma cling load(\"libopencv_core\")\n",
    "#pragma cling load(\"libopencv_imgcodecs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++ Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.488450Z",
     "start_time": "2020-10-20T21:04:21.667739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "\n",
    "#include <cuda_runtime_api.h> \n",
    "\n",
    "#include \"NvInfer.h\" \n",
    "#include \"NvInferPlugin.h\"\n",
    "\n",
    "#undef _OPENMP // Issues with openmp, so disable for now\n",
    "#include <torch/torch.h>\n",
    "\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <opencv2/imgcodecs.hpp>\n",
    "#include \"nlohmann/json.hpp\"\n",
    "#include \"xtl/xbase64.hpp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.510780Z",
     "start_time": "2020-10-20T21:04:28.48973Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto get_file_size(const char* file) {\n",
    "    std::ifstream in(file, std::ifstream::ate | std::ifstream::binary);\n",
    "    return in.tellg(); \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.527270Z",
     "start_time": "2020-10-20T21:04:28.51240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto read_file_data(const char* file, char* data) {\n",
    "    auto sz = get_file_size(file);\n",
    "    std::ifstream f(file, std::ifstream::binary);\n",
    "    f.read(data, sz);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.593730Z",
     "start_time": "2020-10-20T21:04:28.52835Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto get_file_data(const char* file) {\n",
    "    auto sz = get_file_size(file);\n",
    "    std::vector<char> data(sz);\n",
    "    read_file_data(file, data.data());\n",
    "    return data;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.610580Z",
     "start_time": "2020-10-20T21:04:28.59540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto volume(const nvinfer1::Dims& d) {\n",
    "    return std::accumulate(d.d, d.d + d.nbDims, 1, std::multiplies<int64_t>());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T16:15:12.466834Z",
     "start_time": "2020-10-20T16:15:12.366954Z"
    },
    "hidden": true
   },
   "source": [
    "Couldn't get torch::from_blob working in xeus-cling:\n",
    "\n",
    "    https://github.com/jupyter-xeus/xeus-cling/issues/357\n",
    "\n",
    "So I made a cheesy temporary replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.837900Z",
     "start_time": "2020-10-20T21:04:28.61200Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto from_blob(void *ptr, at::IntArrayRef sizes, const at::TensorOptions &options) {\n",
    "    if (options.dtype() == torch::kFloat32) {\n",
    "        auto X = torch::zeros(sizes, options);\n",
    "        auto numel = std::accumulate(sizes.data(), sizes.data()+sizes.size(), 1, std::multiplies<int64_t>());\n",
    "        std::memcpy(X.data_ptr(), ptr, numel*sizeof(float));\n",
    "        return X;\n",
    "    } else {\n",
    "        throw std::runtime_error(\"Only float supported for now\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use opencv to encode torch array into a png, then display with `mime_bundle_repr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.884690Z",
     "start_time": "2020-10-20T21:04:28.83918Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "struct imshow {   \n",
    "    inline imshow(const torch::Tensor& arr, float vmin, float vmax) {\n",
    "        auto arr_float = arr.to(torch::TensorOptions().dtype(torch::kFloat32));\n",
    "        arr_float = (arr_float-vmin)/(vmax-vmin)*255;\n",
    "        auto arr_mat = cv::Mat(arr_float.sizes()[0], arr_float.sizes()[1], CV_32F, arr_float.data_ptr());\n",
    "        std::vector<uchar> arr_png_char;\n",
    "        cv::imencode(\".png\", arr_mat, arr_png_char);\n",
    "        arr_png_str = std::string(arr_png_char.begin(), arr_png_char.end());\n",
    "    }\n",
    "    std::string arr_png_str;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.178769Z",
     "start_time": "2020-10-20T21:04:28.88587Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlohmann::json mime_bundle_repr(const imshow& i) {\n",
    "    auto bundle = nlohmann::json::object();\n",
    "    bundle[\"image/png\"] = xtl::base64encode(i.arr_png_str);\n",
    "    return bundle;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.183701Z",
     "start_time": "2020-10-20T21:04:28.178897Z"
    }
   },
   "outputs": [],
   "source": [
    "class Logger : public nvinfer1::ILogger {\n",
    "    void log(nvinfer1::ILogger::Severity severity, const char* msg) override {\n",
    "        std::cout << msg << std::endl;\n",
    "    }\n",
    "} logger;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.186611Z",
     "start_time": "2020-10-20T21:04:28.183823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "Registered plugin creator - ::NMS_TRT version 1\n",
      "Registered plugin creator - ::Reorg_TRT version 1\n",
      "Registered plugin creator - ::Region_TRT version 1\n",
      "Registered plugin creator - ::Clip_TRT version 1\n",
      "Registered plugin creator - ::LReLU_TRT version 1\n",
      "Registered plugin creator - ::PriorBox_TRT version 1\n",
      "Registered plugin creator - ::Normalize_TRT version 1\n",
      "Registered plugin creator - ::RPROI_TRT version 1\n",
      "Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "Registered plugin creator - ::CropAndResize version 1\n",
      "Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "Registered plugin creator - ::Proposal version 1\n",
      "Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "Registered plugin creator - ::Split version 1\n",
      "Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "Registered plugin creator - ::InstanceNormalization_TRT version 1\n"
     ]
    }
   ],
   "source": [
    "initLibNvInferPlugins(&logger, \"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:28.203066Z",
     "start_time": "2020-10-20T21:04:28.186732Z"
    }
   },
   "outputs": [],
   "source": [
    "auto tensorrt_inference(const char* file_engine, const char* file_batch) {\n",
    "    // Load engine\n",
    "    auto runtime = nvinfer1::createInferRuntime(logger);\n",
    "    auto data_engine = get_file_data(file_engine);\n",
    "    auto engine = runtime->deserializeCudaEngine(data_engine.data(), data_engine.size(), nullptr);\n",
    "    auto context = engine->createExecutionContext();\n",
    "\n",
    "    // Allocate buffers\n",
    "    float *X_h, *y_h, *X_d, *y_d;\n",
    "    const auto nbytes_input  = volume(engine->getBindingDimensions(0))*sizeof(float);\n",
    "    const auto nbytes_output = volume(engine->getBindingDimensions(1))*sizeof(float);\n",
    "    cudaHostAlloc((void**)&X_h,  nbytes_input, cudaHostAllocDefault);\n",
    "    cudaHostAlloc((void**)&y_h, nbytes_output, cudaHostAllocDefault);\n",
    "    cudaMalloc((void**)&X_d,  nbytes_input);  \n",
    "    cudaMalloc((void**)&y_d, nbytes_output);  \n",
    "\n",
    "    // Read batch - assumes this is stored as float and already pre-processed\n",
    "    read_file_data(file_batch, (char*)X_h);\n",
    "\n",
    "    // Inference\n",
    "    cudaStream_t stream;\n",
    "    cudaStreamCreate(&stream);\n",
    "    cudaMemcpyAsync(X_d,  X_h,  nbytes_input,  cudaMemcpyHostToDevice, stream); \n",
    "    context->enqueueV2(std::vector<void*>{X_d, y_d}.data(), stream, nullptr); \n",
    "    cudaMemcpyAsync(y_h, y_d, nbytes_output, cudaMemcpyDeviceToHost, stream); \n",
    "    cudaStreamSynchronize(stream);\n",
    "    // couldnt get torch::from_blob() working with xeus cling, so use from_blob replacement function for now\n",
    "    auto y = from_blob(y_h, {1, 5, 384, 512}, torch::TensorOptions().dtype(torch::kFloat32));\n",
    "    y = y.argmax(1).squeeze(0);\n",
    "    \n",
    "    return y;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:30.894621Z",
     "start_time": "2020-10-20T21:04:28.203216Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deserialize required 679776 microseconds.\n",
      "Allocated persistent device memory of size 2401792\n",
      "Allocated activation device memory of size 16343040\n",
      "Assigning persistent memory blocks for various profiles\n"
     ]
    }
   ],
   "source": [
    "auto file_engine = \"training/attempt_2/model_8.engine\";\n",
    "auto file_batch  = \"batches_trn/X0.raw\";\n",
    "auto y = tensorrt_inference(file_engine, file_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T21:04:31.180593Z",
     "start_time": "2020-10-20T21:04:30.894754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGACAAAAAD+S4VjAAAEWklEQVR4Ae3BQZJihwEFwaqTGW7GzcAnw1J4NPrMpnsBETSvMiXTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk33QCbnwaybec+OXGR5F8x4nfbnwSyTecOLjxQSRfO3F044NIvnbiwY3PIfnaiQc3Pofkayce3Pgckq+deHDjc0i+duLBjc8h+dqJBzc+h+QbThzd+BySbzhxdONzSL7jxL9ufBDJt5z4x41PIvmmE3+78Vkk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk7+nKX868muQtXfnlzEtJ3tCVf515Jcn7uXJ05oUk7+fKgzOvI3k7Vx6deR3J27ny6MzrSN7OlT+ceRnJ27nyhzMvI3k7V/5w5mUk7+fKgzOvI3k/Vx6ceR3JG7pycOaFJO/oyr/OvJDkPV35vzMvJXlbV868mmSaZJpkmmSaZJpsuPCXC/mTLLjwy4U8kgEXfruQB/L5LhxcyJF8vgsHF3Ikn+/C0YUcyOe7cHQhB/L5LhxdyIF8vgtHF3Ign+/Cb//5LxdyIAMuHFzIgSy48NuFHMmEC/+4kCMZceFvF/JIMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJN8kx3/iI/h+R57vwiP4Xkae78Jj+E5FnuHMjPIHmWO0fyI0ie5c6R/AiSZ7lzJD+C5FnuPJCfQPIsd47kR5A8zZ0D+REkT3PnQH4EyfPc+U1+Bskz3fk/+SEkz3UH5MeQTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNMk0yTTJNM+x+YKD6B4+vXPAAAAABJRU5ErkJggg=="
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imshow im(y, 0, 4);\n",
    "im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
